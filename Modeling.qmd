---
title: "Modeling"
format: html
editor: visual
---


#Basic Introduction 

#Split data into testing and training data 

```{r,include= FALSE}
library(tidyverse)
library(tidymodels)
library(yardstick)
library(ggplot2)
library(glmnet)
library(tree)
library(baguette)
library(parsnip)
library(ranger)
```



```{r, include = FALSE }
#Reload the data 
#Read in data and create a tibble 
diabetes_data <- read.csv("diabetes_binary_health_indicators_BRFSS2015.csv")
diabetes_data <- as_tibble(diabetes_data)

#Create vectors for the factor variables 
Diabetes_labels <- c("No Diabetes", "Diabetes")
HighBP_labels <- c("Not High BP", "High BP")
HighChol_labels <- c("Not High Chol", "Chol")
PhysActivity_labels <- c("No","Yes")
Sex_labels <- c("Female","Male")
Age_labels <- c("18-24","25-29","30-34","35-59",
                "40-44","45-49","50-54","55-59",
                "60-64", "65-69", "70-74", "75-79","80 or older")
Income_levels <-c("Less than $10,000",">15000",">20000",">25000",">35000",">50000",
                  ">75000","75000+")



#Mutating the data set to only include the relevant variables models ran and to modify 
#the type of variable 
diabetes_data <- diabetes_data |>
  drop_na() |>
  mutate(
    Diabetes_binary = factor(Diabetes_binary, levels = c(0,1), labels = Diabetes_labels),
    HighBP = factor(HighBP, levels = c(0,1), labels = HighBP_labels),
    HighChol = factor(HighChol, levels = c(0,1), labels = HighChol_labels),
    PhysActivity = factor(PhysActivity, levels = c(0,1), labels = PhysActivity_labels),
    Sex = factor(Sex, levels = c(0,1), labels = Sex_labels),
    Age = factor(Age, levels = 1:13, labels = Age_labels),
    Income = factor(Income, levels = 1:8, labels = Income_levels)
  ) |>
  select(Diabetes_binary,HighBP,HighChol,PhysActivity,Sex,Age,Income,BMI)
```


#Introduction 

On our EDA page, we explored three variables, BMI, High blood pressure, and physical activity, by looking at their distribution of each of the variables in the data set as well as their relationship with diabetes. These variables were picked to determine the cardiometabolic factors effect on diabetes.

Now, we will fit three models, logistic regression model, classification tree, and random forests to look at how they relate with each other in terms of predicting the likelihood of having diabetes. 


#Split data into testing and training set

```{r}
set.seed(123)

model_split <- initial_split(diabetes_data,prop=.7)
test <- testing(model_split)
train <- training(model_split)
diabetes_CV_folds <- vfold_cv(train, 5)
```

#Logistic Regression Model 

A logistic regression model is a model that can predict the probability of a binary variable based on various independent variables. 

In this example, we can apply this model since our dependent variable, diabetes, is binary. We will fit three models, one with BMI, High blood pressure, and PhysActivity, one with those three variables and an interaction on BMI and High blood pressure, and one with the three variables and an interaction on BMI and physical activity.

```{r}
#Model 1: BMI HighBP and PhysActivity
LR1 <- recipe(Diabetes_binary ~ BMI + HighBP + PhysActivity, data=train) |>
  step_normalize(BMI)|>
  step_dummy(HighBP, PhysActivity)

#Model 2: BMI HighBP and PhysActivity and interaction term between
#BMI and highBP 
LR2 <- recipe(Diabetes_binary ~ BMI + HighBP + PhysActivity, data=train) |>
  step_dummy(HighBP, PhysActivity)|>
  step_normalize(all_predictors())|> 
  step_interact(~ BMI:starts_with("HighBP_"))

#Model 3: BMI HighBP and PhysActivity and interaction term between
#BMI and PhysActivity 
LR3 <- recipe(Diabetes_binary ~ BMI + HighBP + PhysActivity, data=train) |>
  step_dummy(HighBP, PhysActivity)|>
  step_normalize(all_predictors())|> 
  step_interact(~ BMI:starts_with("PhysActivity_"))

#Set model type and engine 
LR_spec <- logistic_reg() |>
 set_engine("glm")

#Create workflows
LR1_wkf <- workflow() |>
 add_recipe(LR1) |>
 add_model(LR_spec)
LR2_wkf <- workflow() |>
 add_recipe(LR2) |>
 add_model(LR_spec)
LR3_wkf <- workflow() |>
 add_recipe(LR3) |>
 add_model(LR_spec)

#Fit to CV folds 
LR1_fit <- LR1_wkf |>
 fit_resamples(diabetes_CV_folds, metrics = metric_set(accuracy, mn_log_loss))
LR2_fit <- LR2_wkf |>
 fit_resamples(diabetes_CV_folds, metrics = metric_set(accuracy, mn_log_loss))
LR3_fit <- LR3_wkf |>
 fit_resamples(diabetes_CV_folds, metrics = metric_set(accuracy, mn_log_loss))

rbind(LR1_fit |> collect_metrics(),
 LR2_fit |> collect_metrics(),
 LR3_fit |> collect_metrics()) |>
 mutate(Model = c("Model1", "Model1", "Model2", "Model2", "Model3", "Model3")) |>
 select(Model, everything())

mean(train$Diabetes_binary=="Diabetes")

```

#Classification Tree

A classification tree can be used to predict the outcome of a categorical or binary variable by assigning variables to different classes. This is done by using a fitting process and partitioning by the specific variables into seperate sections. This can be easier to interpret and better for non-linear data than a logistic regression model would be.

For example, in this model we will take BMI, high blood pressure and physical activity and using the fitting process, determine specific branches to find groups that are more likely to have diabetes. 

```{r}
#Create Recipe 
tree_rec <- recipe(Diabetes_binary ~ BMI + HighBP + PhysActivity, data=train) |>
  step_normalize(BMI)|>
  step_dummy(all_nominal_predictors())

tree_rec

tree_mod <- decision_tree(tree_depth = tune(),
  min_n = 20,
  cost_complexity = tune()) |>
  set_engine("rpart") |>
  set_mode("classification")

#Create workflow 
tree_wkf <- workflow() |>
  add_recipe(tree_rec) |>
  add_model(tree_mod)

#Set up my own tuning grid
tree_grid <- grid_regular(cost_complexity(),
                          tree_depth(),
                          levels = c(10, 5))

tree_fits <- tree_wkf |> 
  tune_grid(resamples = diabetes_CV_folds,
            grid = tree_grid,
            metrics=metric_set(accuracy, mn_log_loss))

tree_fits |>
  collect_metrics() 

tree_fits %>%
  collect_metrics() %>%
  mutate(tree_depth = factor(tree_depth)) %>%
  ggplot(aes(cost_complexity, mean, color = tree_depth)) +
  geom_line(size = 1.5, alpha = 0.6) +
  geom_point(size = 2) +
  facet_wrap(~ .metric, scales = "free", nrow = 2) +
  scale_x_log10(labels = scales::label_number()) +
  scale_color_viridis_d(option = "plasma", begin = .9, end = 0)

tree_fits |>
  collect_metrics() |>
  filter(.metric == "mn_log_loss") |>
  arrange(mean)


tree_best_params <- select_best(tree_fits, metric = "mn_log_loss")
tree_best_params

tree_final_wkf <- tree_wkf |>
  finalize_workflow(tree_best_params)

tree_final_fit <- tree_final_wkf |>
  last_fit(model_split,metrics = metric_set(accuracy, mn_log_loss))
tree_final_fit

tree_final_fit |>
  collect_metrics()


```



#Random Forest 

A random forest model is very similar to a classification tree as it similarly predicts the outcome of a categorical variable by splitting each variable into subsets to come to a final decision/ predictions. The difference between the classification tree and a random forest is that a random forest is an ensemble model. This means that this will produce multiple decision trees and will take the average across all of the trees. The classification model will only ever produce one tree. The purpose of this is to reduce over fitting. 


```{r}

ran_forest_rec <- recipe(Diabetes_binary ~ BMI + HighBP + PhysActivity, data=train) |>
  step_normalize(BMI)|>
  step_dummy(all_nominal_predictors())

ran_forest_rec


rf_spec <- rand_forest(mtry = tune()) |>
 set_engine("ranger") |>
 set_mode("classification")

rf_wkf <- workflow() |>
 add_recipe(ran_forest_rec) |>
 add_model(rf_spec)

rf_fit <- rf_wkf |>
 tune_grid(resamples = diabetes_CV_folds,
 grid = 7,
 metrics = metric_set(accuracy, mn_log_loss))

rf_fit |>
 collect_metrics() |>
 filter(.metric == "mn_log_loss") |>
 arrange(mean)

rf_best_params <- select_best(rf_fit, metric = "mn_log_loss")
rf_best_params

rf_final_wkf <- rf_wkf |>
 finalize_workflow(rf_best_params)

rf_final_fit <- rf_final_wkf |>
 last_fit(model_split, metrics = metric_set(accuracy, mn_log_loss))

```

#Final Model Selection 
```{r}
tree_final_fit <- tree_final_wkf |>
  last_fit(model_split,metrics = metric_set(accuracy, mn_log_loss))
tree_final_fit|> collect_metrics()

rf_final_fit <- rf_final_wkf |>
 last_fit(model_split, metrics = metric_set(accuracy, mn_log_loss))
rf_final_fit |> collect_metrics()


LR3_final_fit <- LR3_wkf |>
 last_fit(model_split, metrics = metric_set(accuracy, mn_log_loss)) 

tree_final_fit|> collect_metrics()
rf_final_fit |> collect_metrics()
LR3_final_fit |> collect_metrics()

rbind(tree_final_fit |> collect_metrics(),
rf_final_fit |> collect_metrics(),
 LR3_final_fit |> collect_metrics()) |>
 mutate(Model = c("Classification Model", "Classification Model", "Random Forest", "Random Forest", "Logistic Regression", "Logistic Regression")) |>
 select(Model, everything())


final_model <- rf_final_fit$.workflow[[1]]

```

By looking at the log loss metrics, we can see that random forest has the lowest value for log-loss and is the best model overall of the three that were fit.




